---
title: '"CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features" Summarized'
categories: Papers
header:
  teaser: /assets/teasers/11.jpg
---

 https://arxiv.org/abs/1905.04899 (2019-08-07)

## 1. Cutout + Mixup = CutMix

### Cutout

To prevent a CNN from focusing too much on a small set of intermediate activations or on a small region on input images, random feature removal regularizations have been proposed.

* Dropout: randomly drop hidden activations
* Regional dropout: erasing random regions on the input

Well known strategy for regional dropout is 'Cutout', where you randomly replace random region from images with zeros or noise, before feeding them in to the model.

Cutout lets models attend not only to the most discriminative parts of objects,  but rather to the entire object region.

However, applying cutout greatly reduces the proportion of informative pixels on training images.

### Mixup

Mixup is another augmentation strategy to make a generalizable model. It 'mixes' two random images $x_a$ and $x_b$  from a batch ($\lambda x_a + (1-\lambda)x_b$) and set it's label to $\lambda y_a + (1-\lambda)y_b$.

However Mixup samples suffer from the fact that they are locally ambiguous and unnatural, and therefore confuses the model, especially for localization.

### CutMix

The authors introduce an augment strategy called 'CutMix'. Instead of simply removing pixels, it replaces the removed regions with a patch from another image. The ground truth labels are also mixed proportionally to the number of pixels of combined images. 

With CutMix, the model do not have any uninformative pixel(zero or noise) during training, while retaining the advantages of regional dropout to attend to non-discriminative parts of objects. The added patches further enhance localization ability,  by requiring the model to identify the object from a partial view.

Although Mixup and Cutout enhance ImageNet classiﬁcation accuracy, they decrease the ImageNet localization or object detection performances. On the other hand, CutMix consistently achieves signiﬁcant enhancements across three tasks.

Below is an overview of the results of three techniques on ImageNet classification

![img](https://lh3.googleusercontent.com/SAfoi15zzBoPTrelOak1DCeaYqVrseN8wjs_oBGX79OXmR7bw6DF6IdO_zySkFxxHP2la2OcMEqxLpG1wy8_fohzZlmTvb0XXcrIAZTMf_75xotMFtk_0GU-x_59ejqcO0zFJoj0Lw=w2400)

## 2. CutMix Algorithm

First, we randomly select two images, $x_A$ and $x_B$ from a mini-batch. Then we generate bounding box coordinates $\bf{B}$ $= (r_x, r_y, r_w, r_h)$ indicating the cropping regions on $x_A$ and $x_B$. The regions $\bf{B}$ in $x_A$ is removed and filled in with the patch cropped from $\bf{B}$ of $x_B$. $\bf{B}$ is generated with the following formula.


$$
\lambda \sim Beta(\alpha, \alpha) \\
r_x \sim Unif(0,W) \\
r_y \sim Unif(0,H) \\
r_w = W\sqrt{1-\lambda} \\
r_h = H\sqrt{1-\lambda}
$$


In their experiments, the authors set $\alpha$ to 1, so that combination ratio $\lambda$ is sampled from the uniform distribution (0,1).

This ensures two things.

* Cropped area ratio $\frac{r_wr_h}{WH}=1-\lambda$.
* Cropped width/height ratio is the same as the original width/height ratio.

Then, we will generate a new training sample $(\tilde{x}, \tilde{y})$ from original sample $(x,y)$ using binary mask $\bf{M}$ generated from bounding box $\bf{B}$.


$$
\tilde{x} = \bf{M}*x_A + (\bf{1}-\bf{M})*x_B \\
\tilde{y} = \lambda y_A + (1-\lambda)y_B
$$


Below is a pseudo-code for CutMix.

![img](https://lh3.googleusercontent.com/Ner9ahjnQjoO1AdEXn2xhe557C_Ah0hQT_Lm60wKzqaMAfoejOKRuoTYTALkUCj59dOe4qLG-KV2cIjg9InH6EG0a6pinW2Zn6Ybi7ngrRMpGa6yVFtve-VjSxG2pxWlAQeb33RBYA=w2400)

## 3. Learning Spatially Distributed Representation

### Cam

![gradcam](https://lh3.googleusercontent.com/mQKSnpMeqiK_s9EUANagfD0nYy3JJ-ajGgxvhf9V6Wx5cL9D_Om15BZhkbc8wvXD6RGQY07fpUHHjEP8cQYalJdShmaeE_n2AS7Bad6WOvDlcOczqbkRCNyfCkOLSAEnl2ZrbaLdSw=w2400)

Cutout successfully lets a model focus on less discriminative parts of the object, such as the belly of Saint Bernard, while being inefficient due to unused pixels. Mixup, on the other hand, makes full use of pixels, but introduces unnatural artifacts. The CAM for Mixup, as a result, shows that the model is confused when choosing cues for recognition, which leads to its suboptimal performance in classification and localization. On the other hand, CutMix efficiently improves upon cutout by being able to localize the two object classes accurately.

### WSOL

Weakly supervised object localization (WSOL) task aims to train the classifier to localize target objects by using only the class labels. To localize the target well, it is important to make CNNs extract cues from full object regions and not focus on small discriminant parts of the target. CutMix guides a classifier to attend to broader sets of cues to make decisions, and resulted in  superior performance.

![img](https://lh3.googleusercontent.com/k_9q2gDGHzKAKrO7iojrEJyDeCn1IPvqJ-WR44faDyeiHrvqBIYipPrHKeNoq3IM2oFVHmqqM9kbKN1Ap7uW6tlAvtZbKMqys_F_R-KfxTt0Df8T118ACLK5nxEcnMALmzceC3wC1A=w2400)

![img](https://lh3.googleusercontent.com/lhc_MpFYD4UrMXeJl17QKwwAv0IMaP2qDA50cg9F1-GAuUxPtGNBRn77-rHiDhZ053Vdk5adcC-qqCBYT6DJ3tNTPsz3ZO3kcPfAY5W83Cy1xW62TQaLgl-HUXipQqA_jESkC6QD0g=w2400)

## 4. Robustness to Adversarial Attacks

CutMix significantly improves the robustness to adversarial attacks compared to other augmentation methods.

![img](https://lh3.googleusercontent.com/MOpqsZ6z8-QJyDrsCpMNa_56QLDeaqFBo07no0G0MZ2-AztuJZce7qiK9OXrJZIcIalCt5u0yMk1CFQ5ubWzn5JbsfOCNFiBuVz40YdRd6Qtk7hBUXo-Dd4myStbf9nPw4JoBzCHXA=w2400)

## 5. Experiment Results on ImageNet and CIFAR

![img](https://lh3.googleusercontent.com/kjd73pGwjnsG_wQOKQW0wZfHIzXICG4if9ReERl3vwngSszI2j5gtMDa2eCeu5FKoEavZPuxzQh8cLfGh9mrEkC4Zy2eV70NRsYMzrXvPxxspPjsueaI7clJ8-NTtj1d2xF6QlM53A=w2400)

![img](https://lh3.googleusercontent.com/SRq0FYXRunsZq4XUlCDZI-EKLt5SceUNpeeS5cfBpu_DGRzR0v8NEgv0rJHEOJ60GoOBCiZY0sna6msbgtx07YWrSKLtZ3GsvPk9sfKSeIeJWlZRqFhjxhYzuYPvMLYaT3Yv-VIBzw=w2400)

![img](https://lh3.googleusercontent.com/nzdJFnsQUB6dMiAQAHit2yeoeJuV7ktZei754KtwzgZ2qxMo0WC1FQn_usJqJ6QIE4aXEBpCcFdEa9g0-1OmQazjetbCrF-RdgilDl0t5Hr8RHaV_tDeRYYJPcp7W6S7qE390MvlfA=w2400)

## 6. Variants of CutMix

![img](https://lh3.googleusercontent.com/0LX34Znv0HaRGq2YcJpD6tdXqbOAbWWiOend20Zrjl0qUmAAb4dla_Ls6LBIq_YbJr8QfyEQrXT4C6v8mv3EJn4f_SV0oHKgLB2Coi6dYhlz1PlpxOrYl34T8QhFSWZDFukSwn6mLQ=w2400)

* Center Gaussian CutMix: It samples the box coordinates $r_x, r_y$ according to the Gaussian distribution
* Fixed-size CutMix: It fixes the size of cropping region $r_w, r_h$ at 16x16.
* Scheduled CutMix: It linearly increases the probability to apply CutMix as training progresses.
* One-hot CutMix: It decides the mixed target label by committing to the label of greater patch portion.
* Complete-label CutMix: It assigns the mixed target label as $\tilde{y}=0.5y_A+0.5y_B$ regardless of the combination ratio $\lambda$.
* Different $\alpha$ for Beta distribution, and different layer index to apply cutmix.

The results show that above variants lead to performance degradation compared to the original CutMix.