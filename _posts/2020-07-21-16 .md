---
title: '"Grad-CAM: Visual Explanations from Deep Networks
via Gradient-based Localization" Summarized'
categories: Papers
header:
  teaser: /assets/teasers/11.jpg
---

https://arxiv.org/abs/1610.02391 (2016-10-7)



## 1. Accuracy vs Interpretability

There typically exists a trade-off between accuracy and interpertability(simplicity).

* Classical rule-based systems: interpretable but not accurate
* Deep models: accurate but not interpretable

The authors made deep models interpretable with Grad-CAM.

![](https://lh3.googleusercontent.com/-tTO2xRWhtZ5t5-xOGw2XigADJlQFfBXb8JYJHUA2nn_6Dyffzd2IGx6TOgTEcG-Z55G9vQQng7DoMla_uAXv4C9VGkc4gX1QBGLG6Bkkz8vw3YBkYWBQovU2DsUEJ9mj9hogZNHyA=w2400)



## 2. Grad-CAM Formulation

![](https://lh3.googleusercontent.com/35GP-k_3vtGFObwurEtuV_LoPITbrHLeJSJvUF1zGj2OgZcswuTlsHAkV8EHeDdZXqJ--BUSWKoGdGsz7CtNpcHc9gBr7y1oZjsZN550Qk11BVRp2I4fFcLFR-70sgy0ozIk3OPf7g=w2400)

We first compute $\alpha^c_k$, which

* represents partial linearization of the deep network downstream from $A$

* captures the 'importance' of feature map $k$ for a target class $c$


$$
\alpha^c_k = \frac{1}{Z}\sum_i\sum_j \frac{\partial y^c}{\partial A^k_{i,j}}
$$


* $c$: class index
* $k$: channel index
* $i$: height index, $j$: width index
* $y^c$: score of $c$th class (before softmax) / In general, it could be any differentiable output for any tasks.
* $A$: activation from the last convolution
* $A^k_{i,j}$: number at $(i,j)$ position of $k$th channel of $A$
* $Z$: width * height of $A^k$

Then we compute Grad-Cam $L^c_{Grad-CAM}$


$$
L^c_{Grad-CAM} = ReLU(\sum_k \alpha^c_k A^k)
$$
We apply a ReLU to the linear combination of maps because we are only interested in the features that have a positive influence on the class of interest.



## 3. Grad-CAM generalizes CAM

Previous work, CAM is formulated as follows.


$$
Y^c = \sum_k w^c_k \frac{1}{Z}\sum_i\sum_jA^k_{i,j}
$$


CAM can only be applied to a specific kind of architecture where global average pooled convolutional feature maps are fed directly into softmax. In this condition, the paper shows Grad-CAM is equivalent to CAM, thus it is a strict generalization of CAM.



## 4. Guided Grad-CAM

A good visual explanation from the model for justifying any target category should be 'class discriminative' and 'high-resolution'.

* Guided Backpropagation, Deconvolution: high-resolution but not class-discriminative
* Grad-Cam, CAM: class-discriminative but not high-resolution

The authors upscaled Grad-CAM and multiplied it pixel-wise with guided Backpropagation to create Guided Grad-CAM visualizations that are both high-resolution and class-discriminative.



## 5. Counterfactual Explanations

Counterfactual explanation highlights support for regions that would make the network change its prediction.

It is computed the same way as Grad-CAM but uses negative gradients as shown below.


$$
\alpha^c_k = \frac{1}{Z}\sum_i\sum_j - \frac{\partial y^c}{\partial A^k_{i,j}}
$$
![](https://lh3.googleusercontent.com/M-Fv93xx6OKPGF-Ie0mjtQ3fcaqt3Ld_13JPPsTCu9JxN6L5SHnAieWf_N7o6qV6TrG2L8CoEXkRgfq6dYBojYf-yrrbl_WDfHkXx0JLCUVj221eijLSHgNkwKcUFk1t6E07D-zK-g=w2400)



## 6. Localization Ability

### 1. Weakly-supervised Localization

![](https://lh3.googleusercontent.com/CZL3hYRRliAxGbAB_XJteBuQXtqJXNaC-cM3Xb7w5Co4k1iL6IlpNR2s_zSI5ZCTI-DCFZR25-Z7dwPrr_V7NZxI29ZEpFcdySOEAZ6sHL72e8zuzWQo_z0ThowZo_S3NquxaVyatg=w2400)

### 2. Weakly-supervised Segmentation

![](https://lh3.googleusercontent.com/Icka5pAADRpF2JjPNIKHJmLD83AAArqcWKa40Jo_5vw7T6w80INDNdnpvMWo1FH6BJL1fdY2KlSGR7VDq5rHtK6D9glgZHryrEZewxL_NK8fCO00NFO6o1YFSAAfOgMJGXDvBfqIqw=w2400)

## 7. Pros of Grad-CAM

### 1. Class Discrimination

When viewing Guided Grad-CAM, human subjects can better correctly identify the category being visualized than with Guided Backpropagation.

### 2. Trust

Human subjects are able to identify the more accurate classifier simply from the Guided Grad-CAM, despite both models making identical predictions

### 3. Faithful to the model

Patches which change the CNN score are also patches to which Grad-CAM assign high intensity.

### 4. Analyzing failure modes

With Grad-CAM on failed images, we can see that seemingly unreasonable predictions have reasonable explanations.

![](https://lh3.googleusercontent.com/DZzZ8o6GLRiIwpFQ-My2ke3dMUEyAmq3EsTOPn23E95as76kWqAebZdJbkshzPPe4h9yU2Wu5onP-p7fZqmi94GUvtxgSpaqMoquaHfeUl0VkrrJZfmTKtF2oNRd9onoRBlKACcQwQ=w2400)

### 5. Robust to adversarial noise

![](https://lh3.googleusercontent.com/A-LPOSuZ4a063nYy5y1znBL4ZlkT79HdKKLRJB6v9ixUEi7M0HjFCJQ61M72Ty3Jk1DdLngmzX4Xoi8j8vvQup45w62YkSPW3bgcKSmZ19vjBn0pjVqPo5lDboADFAvgp2LqG_vNwQ=w2400)

### 6. Identifies bias in dataset

![](https://lh3.googleusercontent.com/GxOVXE_yncotYRVnpHAtSk4_8LBY9MsrwQDOmk8Vs658kybjp22CiQwi_CX2txrzke8Dyyuan-QCS8eE7My66XjKvB1x8fowXNiJry11WUvp8oTuENgK_WXARyfBlW1-_wPzejdNUQ=w2400)

## 8. In relate with Words

### 1. Image Captioning

![](https://lh3.googleusercontent.com/LgS8pQ8wg7DnsZaCJdYoz7Y_IjdHnb44oFiWPX-oBGiwbB8ZDMjhkWdFB4X7szEQwRtl9cXrKGlRKkx_k7h6eYFq-iA34EOWW46wyipFTz9NgOMD0GRA0d_oeNT_oHA3tErr7gIvgQ=w2400)

### 2. VQA(Visual Question Answering)

![](https://lh3.googleusercontent.com/uxsSixc0gfg7ynSZryoVaSoKzMYcKvXt5dqnW5mMYkhGeaMCF0qaN1WQG_gQIauTN55UrZ1hrLMzqrA0r4tfdVID386FrDaeDAKArLRrGH28AdHRPyvxGL3fV31WAGFNzilHGpCUNw=w2400)