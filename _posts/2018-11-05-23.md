---
title: Convolution
categories: Deep-Learning Convolutional-Neural-Networks
header:
  teaser: /assets/teasers/7.jpg
---

We convolve filters to input and activate it to get next layer.

![convolution](https://lh3.googleusercontent.com/s66KFpxROYljq5GuJWm6AXKrVcWBkucUccAUPZ9mS4Dc28IUmtMzoTKDl7O43-IDYanQzNkFFG9mjvNrQko5YCEMAebjayV_2xE007Q8tZDm9r_DqBOA_Ck1vabk-GbVi7kfdAg1TQ=w2400)

In the above gif, we are convolving 3x3 filter to an 2-dimensional input with. Our filter is
$\left[ {\begin{array}{}
     1 & 0 & 1\\
     0 & 1 & 0\\
     1 & 0 & 1\\
    \end{array} } \right]$.

We multiply filter with the left-top subset of the input(same size as filter) element-wise, slide it to right/down and repeat until we've arrived at the right-bottom.

# Channels

![convolution channels](https://lh3.googleusercontent.com/slyGpk4A6g_cgWXJwfL5sd9FoUn2GQOgCquafBygfLo-9Vls3YkS1Rn2qXVyi2Uwr2_aFWsyuDP4Sa8OkqHjkT1_b-LA1MdyEpopyxRRRUhNEe6Qhu6g74lZZseTk-jrKuIBbpUEyw=w2400)

In the above image, input is a 6x6 size image. With RGB, there are three **channels** in each pixel so the input shape is 6x6x3. For example, if the left top pixel is red, first channel of that pixel would be 255, second 0, third 0. If the image is black and white, it would only have 1 channel.

Number of channels of filter applied to this input should also be 3.

Also, you can apply multiple filters to the input. Number of filters you apply would be the next layer's number of channels.

# Padding

When doing convolution, pixels in the border contributes less than the inner pixels. By adding pixels of value 0 around the border of the input, we can solve this problem.

![padding](https://lh3.googleusercontent.com/QWXsdYdOhEEOE5zCasxfA0PkdxrYfS4UcRvkc90eiDKlSGi6zQtr5ezlPmFig-qvjEfRSrMUZXjmw23zzJfQqpyCXymU6hXUJmw72i8LZIx21WJF03ySORb9IXAuzjRH4VT5jayKQA=w2400)

The thickness of this added pixels is called **padding**. In the above example, padding is 1.

We call it **same convolution** when we pad so that the output size is the same as the input size. Also convolution without padding is called **valid convolution**.

# Stride

The number of pixels you slide filter is called **stride**.

![stride](https://lh3.googleusercontent.com/dBYi1RDjgqJqr9qcpO8giNvzdxgrPn5rpMmnYEDL9_D71S4-KhdvtoUwHhbbCiAIxsxn7ScAPDtNpyOFdr9-_HHrgLNSYlEv4k3shnTJhbfdJPtnUHbH-wpOVEWfWpySo2Y7EZX8xg=w2400)

In the above example, we are convolving 3x3 filter to a 6x6 input with padding 1 and stride 2.

# Shapes

## Notations

If layer $l$ is a convolution layer with activation shape $n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$;

$f^{[l]}$: filter size

$p^{[l]}$: padding

$s^{[l]}$: stride

$n_f^{[l]}$: number of filters

## Shapes

Each filter: $f^{[l]}\times f^{[l]}\times n_c^{[l]}$

Weights: $f^{[l]} \times f^{[l]} \times n_c^{[l]} \times n_f^{[l]}$

Bias: $n_c^{[l]}$

Output: $n_H^{[l+1]} \times n_W^{[l+1]} \times n_f^{[l]}$, where $n_H^{[l+1]}=\lfloor \frac{n_H^{[l]} + 2p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \rfloor$ (same with $W$)

With multiple examples, $m$ would be multiplied to the front of the shapes. For example, $A^{[l]}: m \times n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$
