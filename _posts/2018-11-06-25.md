---
title: Classic CNNs - LeNet-5, AlexNet, VGG-16
categories: Deep-Learning Convolutional-Neural-Networks
header:
  teaser: /assets/teasers/7.jpg
---



Original Source: https://www.coursera.org/specializations/deep-learning



Note that before feeded into fully connected layer, 3d unit is flattened to 1d.

# LeNet-5

*LeCun et al., 1998. Gradient-based learning applied to document recognition*

![LeNet-5](https://lh3.googleusercontent.com/sOkOeZegdPkzRGBQ21QLPlz14mnuH53Ihs1-ctF3k-yswCmqtQIluz9SQQqxP7BSD4kdMuItwzzfHvWTpb9HyRFrZNA3eRRivgMmTp4KFQdikhEwD22ytZUJlHKvUVnJXWNtC5I-cg=w2400)

* 60k parameters
* As we get deeper, $n_H$ and $n_W$ decrease, and $n_c$ increases
* Structure: conv+pool -> conv+pool ... -> fc
* Average pooling
* Ssigmoid/tanh activation function

# AlexNet

*Krizhevsky et al., 2012. ImageNet classification with deep convolutional neural networks*

![AlexNet](https://lh3.googleusercontent.com/f_jQLGukkvLjR3qEOHCeoPjxKpphsH7IUeCodKcbk1PT7S7F3iRl7wAbubLZ3xDIqGb8m5HnWUbnWRi4-EJ1IOnQaMEm22cQeSFyrbhbdMEn-qBqzsxQ1PNxOt0Y_qYixfbenhLMpA=w2400)

* ~60m parameters
* Structure similar to LeNet-5
* Max pooling
* Same padding
* ReLU activation function

# VGG-16

*Simonyan & Zisserman 2015. Very deep convolutional networks for large-scale image recognition*

![VGG-16](https://lh3.googleusercontent.com/nm5VL2APSFA3ak10JPd_PZIHFGdR1OAeZp_igbjLG1BMRIb-v0PN7k9V18uNAylMA8ZXQVoAL_y6oaBgzgG9ZCAWdWhr7AWhnz4vqpX-tp5rsmMVeECer64aaQllVFthWuxHP1s7Xg=w2400)

* ~138m parameters
* Structure similar to AlexNet but uses multiple convs before pool
