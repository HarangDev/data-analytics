---
title: How I set Windows GPU Environment for Data Science and Machine Learning in Python
categories: Tips
---

## 1. Install Anaconda

https://www.anaconda.com/distribution/

Anaconda is a free and open-source distribution of the Python and R programming languages for scientific computing (data science, machine learning applications, large-scale data processing, predictive analytics, etc.), that aims to simplify package management and deployment. Package versions are managed by the package management system conda.

## 2. Set up Conda Env

Go to cmd, type `conda create -n gpu` to create environement named 'gpu'.

## 3. Set OpenCL Environments

1. Make sure you have nvidia gpu and have nvidia graphic drivers. (https://www.nvidia.com/Download/index.aspx
2. Install Visual Studio. From Visual Studio installer, check 'Desktop development with C++' and install. (https://visualstudio.microsoft.com)
3. Install CUDA 10.0. (https://developer.nvidia.com/cuda-10.0-download-archive) Latest version is 10.1 but since Tensorflow supports 10.0(https://www.tensorflow.org/install/gpu), download 10.0.
4. Install latest cuDNN for CUDA 10.0. (https://developer.nvidia.com/cudnn) You have to login for Nvidia to download it. You need to unzip and move files to specific directory. You can refer to https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-windows.
5. Reboot your computer.

## 4. Set LightGBM GPU Environments

1. Install Cmake. (https://cmake.org/download/)
2. Install Boost Binaries 'boost_1_69_0-msvc-14.1-64.exe'. (https://bintray.com/boostorg/release/boost-binaries/1.69.0#files)


## 5. Install Packages

Go to your created environment gpu by typing `conda activate gpu` at cmd.

Then, type `conda install numpy pandas matplotlib seaborn scikit-learn tqdm` to install packages available at conda.

Then, type `pip install tensorflow-gpu catboost xgboost optuna multiprocess category_encoders tables` to install extra packages.

Then, type `pip install lightgbm --install-option=--gpu` to install lightgbm gpu version.

What are these packages for?
1. [NumPy](http://www.numpy.org/): NumPy is the fundamental package for scientific computing with Python.
2. [Pandas](https://pandas.pydata.org/): Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.
3. [Matplotlib](https://matplotlib.org/): Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.
4. [seaborn](https://seaborn.pydata.org/): Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.
5. [scikit-learn](https://scikit-learn.org/): Scikit-learn is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.
6. [tqdm](https://github.com/tqdm/tqdm): tqdm displays progress bar when doing loops.
7. [TensorFlow](https://www.tensorflow.org/): TensorFlow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks.
8. [LightGBM](https://lightgbm.readthedocs.io/en/latest/): LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is fast and accurate.
9. [CatBoost](https://tech.yandex.com/catboost/): CatBoost is a machine learning method based on gradient boosting over decision trees. It is really fast on GPUs.
10. [XGBoost](https://xgboost.readthedocs.io/en/latest/index.html): XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It was once used by many kagglers, but is diminishing due to arise of LightGBM and CatBoost.
11. [Optuna](https://optuna.org/): Optuna is a define-by-run bayesian hyperparameter optimization framework. It supports multiprocessing and pruning when searching.
12. [multiprocess](https://github.com/uqfoundation/multiprocess): It is a lot easier to use this libarary rather than defualt 'multiprocessing'.
13. [Category Encoders](http://contrib.scikit-learn.org/categorical-encoding): A set of scikit-learn-style transformers for encoding categorical variables into numeric with different techniques.
14. Tables: This enables pandas to save and load dataframes or series with hdf format.
