---
title: Comparing Different Epsilons
categories: Reinforcement-Learning
header:
  teaser: /assets/teasers/8.jpg
---

```python
import numpy as np
import matplotlib.pyplot as plt
```


```python
class Bandit:

    def __init__(self, m):
        self.m = m
        self.mean = 0
        self.N = 0

    def pull(self):
        return np.random.randn() + self.m

    def update(self, x):
        self.N += 1
        self.mean = (1-1/self.N)*self.mean + 1/self.N*x
```


```python
def run_experiment(m1, m2, m3, eps, N):
    bandits = [Bandit(m1), Bandit(m2), Bandit(m3)]
    data = np.empty(N)
    for i in range(N):
        p = np.random.random()
        if p < eps:
            j = np.random.choice(3)
        else:
            j = np.argmax([bandit.mean for bandit in bandits])
        x = bandits[j].pull()
        bandits[j].update(x)
        data[i] = x
    cumulative_average = np.cumsum(data) / (np.arange(N)+1)

    print('mean reward for each choice after {} trials with epsilon={}'.format(N, eps))
    print([b.mean for b in bandits])

    return cumulative_average
```


```python
if __name__ == '__main__':
    c_1 = run_experiment(1.0, 2.0, 3.0, 0.1, 100000)
    c_05 = run_experiment(1.0, 2.0, 3.0, 0.05, 100000)
    c_01 = run_experiment(1.0, 2.0, 3.0, 0.01, 100000)

    # log scale plot
    plt.figure(figsize=(20,10))
    plt.plot(c_1, label='eps = 0.1')
    plt.plot(c_05, label='eps = 0.05')
    plt.plot(c_01, label='eps = 0.01')
    plt.title('Cumulative average reward for different epsilons (when mean rewards for each choice are 1,2,3 and total number of trials is 100000)')
    plt.legend()
    plt.xscale('log')
    plt.show()
```

    mean reward for each choice after 100000 trials with epsilon=0.1
    [0.989801573108708, 1.9982366958816056, 3.0005827007404253]
    mean reward for each choice after 100000 trials with epsilon=0.05
    [0.9845208589441511, 1.9933544629422282, 3.0010587702351277]
    mean reward for each choice after 100000 trials with epsilon=0.01
    [1.0876847387604258, 1.9322175171867086, 2.9983011295992243]



![png](https://lh3.googleusercontent.com/XIXfC8ACrUKb9wL_qKoFyuIlmjNa1va05c0YM06KjtxVQc6mr8cn1VofKBVOLd-oTZmc3gdR9cLvLpkhiwGo0Hvj9-6WsD3cMIDu05YIHU0gB52vYCj7AkATnWsE9XUAvhR42nUKVg=w2400)

From the above graph, we can know that with smaller epsilons, we are slower on focusing on the best machine, but gets more rewards after finding one.
